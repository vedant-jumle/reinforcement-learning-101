# LLM Pentesting Agent Project Plan

## Project Overview

Fine-tune an instruction-following LLM to solve CTF challenges (TryHackMe/HackTheBox) through an agentic workflow with tool calling capabilities.

## Architecture

```
┌─────────────────────────────────────────┐
│  Agent Controller (Custom Code)         │
│  - Maintains state/context              │
│  - Orchestrates tool execution          │
│  - Manages conversation history         │
│  - Implements ReAct/custom loop         │
└───────────┬─────────────────────────────┘
            │
            ▼
┌─────────────────────────────────────────┐
│  Fine-tuned Instruct LLM                │
│  - Tool calling (nmap, gobuster, etc.)  │
│  - Reasoning about observations         │
│  - Planning next steps                  │
│  - Domain knowledge (pentesting)        │
└───────────┬─────────────────────────────┘
            │
            ▼
┌─────────────────────────────────────────┐
│  Tool Execution Layer (Sandboxed)       │
│  - Kali Linux tools                     │
│  - Safe execution environment           │
│  - Result parsing & formatting          │
└─────────────────────────────────────────┘
```

**Key Design Decisions**:
- Agentic workflow gives control over reasoning loop
- Fine-tuned LLM specialized for pentesting tool use
- Independent iteration on agent logic AND model capabilities
- Sandboxed execution for safety

---

## 1. Dataset Creation Strategy

### Target
50-100 HackTheBox retired machines, structured as conversation format

### Data Format

```json
{
  "machine": "Lame",
  "difficulty": "Easy",
  "conversation": [
    {
      "role": "system",
      "content": "You are a penetration testing assistant. Use available tools to find and exploit vulnerabilities."
    },
    {
      "role": "user",
      "content": "Target IP: 10.10.10.3. Find vulnerabilities and capture user.txt and root.txt flags."
    },
    {
      "role": "assistant",
      "content": null,
      "tool_calls": [{
        "name": "nmap",
        "arguments": {"target": "10.10.10.3", "flags": "-sV -sC"}
      }]
    },
    {
      "role": "tool",
      "name": "nmap",
      "content": "PORT   STATE SERVICE VERSION\n21/tcp open  ftp     vsftpd 2.3.4\n22/tcp open  ssh     OpenSSH 4.7p1\n139/tcp open  netbios-ssn Samba smbd 3.X"
    },
    {
      "role": "assistant",
      "content": "Interesting - vsftpd 2.3.4 has a known backdoor vulnerability (CVE-2011-2523). Let me also check the Samba version.",
      "tool_calls": [{
        "name": "searchsploit",
        "arguments": {"query": "vsftpd 2.3.4"}
      }]
    }
    // ... continue conversation until flags captured
  ]
}
```

### Data Collection Workflow

1. **Solve machine yourself** - Take detailed notes during the process
2. **Convert to conversation format** - Structure as tool-calling dialogue
3. **Include failed attempts** - Critical for learning realistic exploration
4. **Annotate reasoning explicitly** - Make thought process clear

### Data Quality Guidelines

- **Balance difficulty**: 70% Easy, 20% Medium, 10% Hard
- **Diverse attack vectors**: Web exploits, privilege escalation, binary exploitation, etc.
- **Show exploration**: Include dead-ends and pivots, not just the golden path
- **Explicit reasoning**: "I'm checking X because Y" not just tool calls
- **Complete solutions**: From initial scan to root flag capture

---

## 2. Tool Set Definition

### Phase 1: Essential Tools (Start Here)

| Tool | Purpose | Priority |
|------|---------|----------|
| `nmap` | Port scanning and service enumeration | P0 |
| `gobuster` / `ffuf` | Directory/file enumeration | P0 |
| `searchsploit` | Exploit database search | P0 |
| `bash` | General command execution | P0 |
| `file_read` | Reading files from target | P0 |
| `msfconsole` | Metasploit for known exploits | P1 |

### Phase 2: Advanced Tools (Later)

| Tool | Purpose | Priority |
|------|---------|----------|
| `burpsuite` | Web proxy/manipulation | P2 |
| `sqlmap` | SQL injection automation | P2 |
| `hydra` | Password/hash cracking | P2 |
| `nikto` | Web vulnerability scanner | P2 |

### Tool Schema Format

Each tool needs a JSON schema for the LLM to use:

```python
TOOLS = {
    "nmap": {
        "description": "Network port scanner for service discovery and version detection",
        "parameters": {
            "target": {
                "type": "string",
                "required": True,
                "description": "Target IP address or hostname"
            },
            "flags": {
                "type": "string",
                "required": False,
                "default": "-sV",
                "description": "Nmap flags (e.g., '-sV -sC' for version detection and default scripts)"
            }
        },
        "returns": "Text output of nmap scan results"
    },

    "gobuster": {
        "description": "Directory and file enumeration tool for web servers",
        "parameters": {
            "url": {
                "type": "string",
                "required": True,
                "description": "Target URL (e.g., 'http://10.10.10.3')"
            },
            "wordlist": {
                "type": "string",
                "required": False,
                "default": "/usr/share/wordlists/dirb/common.txt",
                "description": "Path to wordlist file"
            },
            "extensions": {
                "type": "string",
                "required": False,
                "description": "File extensions to search for (e.g., 'php,html,txt')"
            }
        },
        "returns": "List of discovered directories and files"
    },

    "searchsploit": {
        "description": "Search ExploitDB for known vulnerabilities and exploits",
        "parameters": {
            "query": {
                "type": "string",
                "required": True,
                "description": "Search term (service name, version, CVE, etc.)"
            }
        },
        "returns": "List of matching exploits with paths"
    },

    "bash": {
        "description": "Execute arbitrary bash command (use carefully!)",
        "parameters": {
            "command": {
                "type": "string",
                "required": True,
                "description": "Bash command to execute"
            }
        },
        "returns": "Command output (stdout/stderr)"
    },

    "file_read": {
        "description": "Read file contents from target system",
        "parameters": {
            "path": {
                "type": "string",
                "required": True,
                "description": "File path on target system"
            }
        },
        "returns": "File contents"
    }
}
```

---

## 3. Fine-tuning Strategy

### Model Selection

**Start With**:
- **Llama 3.2 3B** - Good instruction following, manageable size
- **Qwen 2.5 7B** - Excellent reasoning, still fits on single GPU with QLoRA

**Later Try** (if you need more reasoning power):
- **Llama 3.1 8B** - Stronger reasoning capabilities
- **Mistral 7B** - Good balance of size/performance

### Training Configuration

```python
# QLoRA config (if GPU memory constrained)
from transformers import BitsAndBytesConfig

bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_use_double_quant=True
)

# LoRA config
from peft import LoraConfig

lora_config = LoraConfig(
    r=64,  # Might need higher rank for complex reasoning
    lora_alpha=16,
    target_modules=[
        "q_proj", "k_proj", "v_proj", "o_proj",  # Attention
        "gate_proj", "up_proj", "down_proj"       # MLP
    ],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)
```

### Training Data Format

Use function calling format (OpenAI-style or adapt to your model's format):

```python
# Example training sample
{
    "messages": [
        {"role": "system", "content": "You are a penetration testing assistant..."},
        {"role": "user", "content": "Target: 10.10.10.3. Find vulnerabilities."},
        {
            "role": "assistant",
            "content": null,
            "tool_calls": [{
                "id": "call_1",
                "type": "function",
                "function": {
                    "name": "nmap",
                    "arguments": '{"target": "10.10.10.3", "flags": "-sV -sC"}'
                }
            }]
        },
        {
            "role": "tool",
            "tool_call_id": "call_1",
            "name": "nmap",
            "content": "PORT   STATE SERVICE VERSION\n21/tcp open  ftp..."
        }
    ]
}
```

### Hyperparameters

```python
training_args = TrainingArguments(
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,  # Effective batch size = 16
    num_train_epochs=3,
    learning_rate=2e-4,
    fp16=True,  # or bf16 if supported
    logging_steps=10,
    save_strategy="epoch",
    evaluation_strategy="epoch",
    warmup_ratio=0.03,
    lr_scheduler_type="cosine",
    max_grad_norm=0.3,
)
```

---

## 4. Agent Implementation

### Simple ReAct-style Agent

```python
class PentestAgent:
    """
    Agentic workflow for penetration testing using fine-tuned LLM.
    Implements ReAct-style reasoning loop.
    """

    def __init__(self, model, tools, max_iterations=50):
        """
        Args:
            model: Fine-tuned LLM with tool calling capabilities
            tools: Dict of available tools {name: tool_function}
            max_iterations: Max reasoning steps before giving up
        """
        self.model = model
        self.tools = tools
        self.max_iterations = max_iterations

    def solve(self, target_ip, conversation_history=None):
        """
        Main solving loop for a target machine.

        Args:
            target_ip: Target IP address
            conversation_history: Optional prior conversation

        Returns:
            Full conversation history with flags (if found)
        """
        messages = conversation_history or []
        messages.append({
            "role": "system",
            "content": "You are a penetration testing assistant. Use available tools to find and exploit vulnerabilities."
        })
        messages.append({
            "role": "user",
            "content": f"Target: {target_ip}. Find and exploit vulnerabilities to capture user.txt and root.txt flags."
        })

        for iteration in range(self.max_iterations):
            print(f"\n=== Iteration {iteration + 1}/{self.max_iterations} ===")

            # 1. Get model response (with potential tool calls)
            response = self.model.generate(
                messages,
                temperature=0.7,
                max_tokens=1024
            )

            # 2. Add assistant response to conversation
            messages.append({
                "role": "assistant",
                "content": response.content,
                "tool_calls": response.tool_calls
            })

            # 3. Execute any tool calls
            if response.tool_calls:
                for tool_call in response.tool_calls:
                    print(f"Tool: {tool_call.name}")
                    print(f"Args: {tool_call.arguments}")

                    # Execute tool (sandboxed!)
                    result = self.execute_tool(
                        tool_call.name,
                        tool_call.arguments
                    )

                    # Add tool result to conversation
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "name": tool_call.name,
                        "content": result
                    })

                    print(f"Result: {result[:200]}...")  # Preview

            # 4. Check for completion (flags captured)
            if self.check_completion(messages):
                print("\n✓ Flags captured!")
                return {
                    "success": True,
                    "iterations": iteration + 1,
                    "conversation": messages,
                    "flags": self.extract_flags(messages)
                }

            # 5. Check if agent is stuck (no tool calls, repetitive)
            if self.is_stuck(messages):
                print("\n✗ Agent appears stuck")
                break

        return {
            "success": False,
            "iterations": self.max_iterations,
            "conversation": messages,
            "flags": self.extract_flags(messages)
        }

    def execute_tool(self, tool_name, arguments):
        """
        Execute a tool in sandboxed environment.

        IMPORTANT: Must implement proper sandboxing!
        - Docker container per target?
        - Dedicated VM?
        - Network isolation?
        """
        if tool_name not in self.tools:
            return f"Error: Unknown tool '{tool_name}'"

        try:
            # Parse arguments (JSON string → dict)
            args = json.loads(arguments) if isinstance(arguments, str) else arguments

            # Execute tool
            result = self.tools[tool_name](**args)

            return result

        except Exception as e:
            return f"Error executing {tool_name}: {str(e)}"

    def check_completion(self, messages):
        """Check if both flags (user.txt and root.txt) have been captured."""
        conversation_text = "\n".join([
            msg.get("content", "") or ""
            for msg in messages
        ])

        # Look for flag patterns
        user_flag = bool(re.search(r'user\.txt[:\s]+([a-f0-9]{32})', conversation_text, re.I))
        root_flag = bool(re.search(r'root\.txt[:\s]+([a-f0-9]{32})', conversation_text, re.I))

        return user_flag and root_flag

    def extract_flags(self, messages):
        """Extract captured flags from conversation."""
        conversation_text = "\n".join([
            msg.get("content", "") or ""
            for msg in messages
        ])

        flags = {}

        user_match = re.search(r'user\.txt[:\s]+([a-f0-9]{32})', conversation_text, re.I)
        if user_match:
            flags['user'] = user_match.group(1)

        root_match = re.search(r'root\.txt[:\s]+([a-f0-9]{32})', conversation_text, re.I)
        if root_match:
            flags['root'] = root_match.group(1)

        return flags

    def is_stuck(self, messages, lookback=3):
        """Detect if agent is stuck (repetitive actions, no progress)."""
        if len(messages) < lookback * 2:
            return False

        recent = messages[-lookback:]

        # No tool calls in recent messages
        has_tool_calls = any(
            msg.get("tool_calls")
            for msg in recent
            if msg.get("role") == "assistant"
        )
        if not has_tool_calls:
            return True

        # Same tool called repeatedly with same args (primitive check)
        tool_calls = [
            (msg.get("tool_calls", [{}])[0].get("name"),
             msg.get("tool_calls", [{}])[0].get("arguments"))
            for msg in recent
            if msg.get("role") == "assistant" and msg.get("tool_calls")
        ]

        if len(tool_calls) >= 2 and len(set(tool_calls)) == 1:
            return True  # Same tool call repeated

        return False
```

### Tool Execution Layer (Stub)

```python
def execute_nmap(target, flags="-sV"):
    """Execute nmap scan (must be sandboxed!)"""
    # TODO: Implement sandboxing (Docker, VM, etc.)
    cmd = f"nmap {flags} {target}"
    result = subprocess.run(
        cmd.split(),
        capture_output=True,
        text=True,
        timeout=60
    )
    return result.stdout

def execute_gobuster(url, wordlist="/usr/share/wordlists/dirb/common.txt", extensions=None):
    """Execute gobuster directory enumeration"""
    cmd = f"gobuster dir -u {url} -w {wordlist}"
    if extensions:
        cmd += f" -x {extensions}"

    result = subprocess.run(
        cmd.split(),
        capture_output=True,
        text=True,
        timeout=300
    )
    return result.stdout

# Map tool names to functions
TOOLS = {
    "nmap": execute_nmap,
    "gobuster": execute_gobuster,
    # ... etc
}
```

---

## 5. Evaluation Framework

### Metrics to Track

```python
{
    "machine": "Lame",
    "difficulty": "Easy",
    "success": True,
    "flags_captured": {
        "user": "e3d0796d002a446c0e622226f42e9672",
        "root": "92caac3be140ef409e45721348a4e9df"
    },
    "iterations": {
        "total": 15,
        "to_user_flag": 8,
        "to_root_flag": 15
    },
    "tools_used": ["nmap", "searchsploit", "msfconsole", "bash"],
    "tool_call_counts": {
        "nmap": 2,
        "searchsploit": 3,
        "msfconsole": 1,
        "bash": 5
    },
    "failed_attempts": 2,
    "reasoning_quality": {
        "correct_steps": 12,
        "total_steps": 14,
        "accuracy": 0.857
    },
    "time_elapsed_seconds": 127.3
}
```

### Evaluation Script

```python
class PentestEvaluator:
    """Evaluate agent performance on held-out machines."""

    def __init__(self, agent, test_machines):
        self.agent = agent
        self.test_machines = test_machines

    def evaluate(self, save_path="evaluation_results.json"):
        results = []

        for machine in self.test_machines:
            print(f"\n{'='*60}")
            print(f"Testing: {machine['name']} ({machine['difficulty']})")
            print(f"{'='*60}")

            start_time = time.time()

            # Run agent
            result = self.agent.solve(
                target_ip=machine['ip'],
                conversation_history=None
            )

            elapsed = time.time() - start_time

            # Evaluate result
            eval_result = {
                "machine": machine['name'],
                "difficulty": machine['difficulty'],
                "success": result['success'],
                "flags_captured": result['flags'],
                "iterations": result['iterations'],
                "time_elapsed_seconds": elapsed,
                # ... extract other metrics from result['conversation']
            }

            results.append(eval_result)

            # Print summary
            self.print_summary(eval_result)

        # Save results
        with open(save_path, 'w') as f:
            json.dump(results, f, indent=2)

        # Overall statistics
        self.print_overall_stats(results)

        return results

    def print_summary(self, result):
        """Print single machine result."""
        status = "✓ SUCCESS" if result['success'] else "✗ FAILED"
        print(f"\n{status}")
        print(f"Flags: {result['flags_captured']}")
        print(f"Iterations: {result['iterations']}")
        print(f"Time: {result['time_elapsed_seconds']:.1f}s")

    def print_overall_stats(self, results):
        """Print aggregate statistics."""
        total = len(results)
        successes = sum(1 for r in results if r['success'])

        print(f"\n{'='*60}")
        print("OVERALL STATISTICS")
        print(f"{'='*60}")
        print(f"Success Rate: {successes}/{total} ({100*successes/total:.1f}%)")
        print(f"Avg Iterations: {np.mean([r['iterations'] for r in results]):.1f}")
        print(f"Avg Time: {np.mean([r['time_elapsed_seconds'] for r in results]):.1f}s")

        # By difficulty
        for difficulty in ["Easy", "Medium", "Hard"]:
            subset = [r for r in results if r['difficulty'] == difficulty]
            if subset:
                succ = sum(1 for r in subset if r['success'])
                print(f"{difficulty}: {succ}/{len(subset)} ({100*succ/len(subset):.1f}%)")
```

---

## 6. Proposed Timeline

### Week 1-2: Infrastructure Setup
- [ ] Set up sandbox environment (Docker containers? Dedicated VM?)
- [ ] Implement basic agent loop (ReAct-style)
- [ ] Define tool schemas for Phase 1 tools
- [ ] Implement tool execution layer with safety checks
- [ ] Test with GPT-4/Claude as baseline (no fine-tuning yet)

**Deliverable**: Working agent that can solve 1-2 easy machines with GPT-4

---

### Week 3-6: Data Collection
- [ ] Solve 50 HackTheBox retired machines manually
- [ ] Document each in conversation format (tool calls + reasoning)
- [ ] Include failed attempts and exploration paths
- [ ] Balance difficulty: ~35 Easy, ~10 Medium, ~5 Hard
- [ ] Create train/val/test splits (70/15/15)

**Deliverable**: Dataset of 50 machines in tool-calling conversation format

---

### Week 7-8: Fine-tuning v1
- [ ] Train on first 35 machines (training set)
- [ ] Use QLoRA for efficiency (Llama 3.2 3B or Qwen 2.5 7B)
- [ ] Evaluate on 7-8 held-out validation machines
- [ ] Analyze failure modes (where does it get stuck?)
- [ ] Compare to GPT-4 baseline

**Deliverable**: Fine-tuned model v1 with evaluation metrics

---

### Week 9-10: Iteration & Refinement
- [ ] Add more training data based on failure analysis
- [ ] Refine tool schemas (add missing tools, fix arg formats)
- [ ] Improve agent logic (better stuck detection, retry strategies)
- [ ] Fine-tune v2 with expanded dataset
- [ ] Final evaluation on test set

**Deliverable**: Fine-tuned model v2, comprehensive evaluation report

---

## 7. Open Questions

### Infrastructure
1. **GPU access**: What compute do you have available?
   - Single GPU (24GB)? → Qwen 2.5 7B with QLoRA
   - Single GPU (16GB)? → Llama 3.2 3B with QLoRA
   - Multi-GPU or cloud? → Larger models possible

2. **Sandbox environment**: How will you safely execute commands?
   - Docker containers per target machine?
   - Dedicated VMs with snapshots?
   - WSL2 isolated environments?
   - Network isolation strategy?

3. **HackTheBox access**:
   - VIP subscription for retired machines?
   - Local vulnerable VMs (VulnHub, etc.)?
   - Mix of both?

### Scope
4. **Attack surface**: What to focus on initially?
   - Web exploits only (SQLi, XSS, LFI, etc.)?
   - Include privilege escalation (Linux/Windows)?
   - Binary exploitation?
   - Start narrow, expand later?

5. **Tool complexity**:
   - Start with CLI tools only?
   - Include GUI tools (Burp Suite)?
   - Manual exploit writing vs Metasploit?

### Evaluation
6. **Success criteria**: What counts as "solved"?
   - Both flags captured (user + root)?
   - Just initial foothold?
   - Partial credit for correct enumeration?

7. **Comparison baseline**:
   - GPT-4 with same agent framework?
   - Claude 3.5 Sonnet?
   - Existing pentesting tools (AutoPwn, etc.)?

---

## 8. Risks & Mitigations

### Risk 1: Data Collection is Slow
**Impact**: May not get 50 machines in 4 weeks
**Mitigation**:
- Use public CTF writeups from GitHub to supplement
- Focus on quality over quantity (30 high-quality > 50 rushed)
- Consider using existing pentesting datasets (if available)

### Risk 2: Model Doesn't Learn Tool Use Well
**Impact**: Fine-tuned model worse than GPT-4 baseline
**Mitigation**:
- Start with model that already does function calling (Llama 3.1+)
- Use instruction format that model was trained on
- Validate tool calling works before collecting 50 machines
- Consider few-shot prompting instead of fine-tuning if faster

### Risk 3: Sandbox Environment Breaks
**Impact**: Can't safely execute tools
**Mitigation**:
- Use well-tested containerization (Docker with network isolation)
- Have kill switches and timeouts
- Test sandbox thoroughly before data collection
- Consider using HackTheBox VPN (already sandboxed)

### Risk 4: Evaluation is Subjective
**Impact**: Hard to measure progress
**Mitigation**:
- Focus on objective metrics (flags captured yes/no)
- Use same agent framework for all models (fair comparison)
- Manual review of failure modes for qualitative insights
- Track multiple metrics (not just success rate)

---

## 9. Success Criteria

### Minimum Viable Product (Week 8)
- [ ] Agent can solve >20% of Easy machines in test set
- [ ] Fine-tuned model outperforms random tool selection
- [ ] Tool calling works reliably (>90% valid tool calls)
- [ ] Complete data collection pipeline documented

### Target Performance (Week 10)
- [ ] Agent solves >50% of Easy machines in test set
- [ ] Agent solves >20% of Medium machines in test set
- [ ] Fine-tuned model competitive with GPT-4 baseline
- [ ] Comprehensive evaluation report with failure analysis

### Stretch Goals
- [ ] Agent solves >70% of Easy machines
- [ ] Blog post series documenting the journey
- [ ] Open-source release of agent framework
- [ ] Video demonstrations of agent solving machines

---

## 10. Next Steps

### Immediate (This Week)
1. **Set up development environment**
   - Install necessary tools (nmap, gobuster, etc.)
   - Set up Kali Linux VM or Docker container
   - Test tool execution

2. **Implement basic agent**
   - Code the ReAct loop
   - Define initial tool schemas
   - Test with GPT-4/Claude API

3. **Solve 3 machines manually**
   - Document in conversation format
   - Validate data format works
   - Identify any issues early

### Week 2
4. **Finalize architecture**
   - Sandbox execution strategy
   - Tool schema format
   - Agent stopping criteria

5. **Continue data collection**
   - Target: 10 machines documented
   - Refine format based on learnings

### Week 3+
6. **Scale data collection**
   - 2-3 machines per day
   - Build training dataset

7. **Prepare for fine-tuning**
   - Set up training environment
   - Test QLoRA configuration
   - Prepare data loaders

---

## 11. Resources

### HackTheBox
- Retired machines: https://www.hackthebox.com/machines/retired
- VIP subscription required for older machines
- API access for automation: https://www.hackthebox.com/api

### Tools & Frameworks
- **Fine-tuning**: Axolotl, LLamaFactory, Unsloth, HuggingFace TRL
- **Agent frameworks**: LangChain, LlamaIndex, Claude Agent SDK
- **Pentesting tools**: Kali Linux, SecLists wordlists, ExploitDB

### Datasets (Supplementary)
- Public CTF writeups: GitHub search "CTF writeup"
- HackTheBox writeups: https://0xdf.gitlab.io/ (excellent quality)
- VulnHub machines: https://www.vulnhub.com/

### Papers & References
- **Toolformer** (Schick et al., 2023): Teaching LLMs to use tools
- **ReAct** (Yao et al., 2023): Reasoning + Acting
- **Tree of Thoughts** (Yao et al., 2023): Advanced reasoning
- **Function Calling** (OpenAI): https://platform.openai.com/docs/guides/function-calling

---

## Repository Structure (Proposed)

```
llm-pentest-agent/
├── README.md
├── requirements.txt
├── .gitignore
│
├── agent/
│   ├── __init__.py
│   ├── pentest_agent.py       # Main agent class
│   ├── tools.py                # Tool definitions & execution
│   └── schemas.py              # Tool schemas
│
├── data/
│   ├── machines/               # Raw machine data
│   │   ├── lame.json
│   │   ├── legacy.json
│   │   └── ...
│   ├── splits/                 # Train/val/test splits
│   │   ├── train.json
│   │   ├── val.json
│   │   └── test.json
│   └── processed/              # Formatted for training
│       └── training_data.jsonl
│
├── models/
│   ├── v1/                     # Fine-tuned model v1
│   ├── v2/                     # Fine-tuned model v2
│   └── checkpoints/
│
├── evaluation/
│   ├── evaluator.py            # Evaluation framework
│   ├── results/                # Evaluation outputs
│   └── metrics.py              # Metric computation
│
├── sandbox/
│   ├── Dockerfile              # Sandbox environment
│   ├── docker-compose.yml
│   └── setup.sh
│
├── training/
│   ├── train.py                # Fine-tuning script
│   ├── config.yaml             # Hyperparameters
│   └── prepare_data.py         # Data preprocessing
│
└── notebooks/
    ├── 01_baseline_gpt4.ipynb
    ├── 02_data_collection.ipynb
    ├── 03_training_v1.ipynb
    └── 04_evaluation.ipynb
```

---

## Appendix: Example Tool Execution

### Example: Nmap Tool

```python
import subprocess
import json

def execute_nmap_safe(target, flags="-sV", timeout=60):
    """
    Execute nmap with safety checks.

    Safety considerations:
    - Validate target IP (no command injection)
    - Whitelist allowed flags
    - Set timeout to prevent hanging
    - Run in isolated network namespace
    """

    # 1. Validate target
    if not is_valid_ip(target):
        return {"error": "Invalid target IP"}

    # 2. Whitelist flags (prevent command injection)
    allowed_flags = ["-sV", "-sC", "-p", "-A", "-sS", "-O"]
    flag_parts = flags.split()
    if not all(any(f.startswith(allowed) for allowed in allowed_flags) for f in flag_parts):
        return {"error": f"Disallowed flags: {flags}"}

    # 3. Build command
    cmd = ["nmap"] + flag_parts + [target]

    # 4. Execute in sandbox (Docker example)
    try:
        result = subprocess.run(
            ["docker", "exec", "pentest-sandbox"] + cmd,
            capture_output=True,
            text=True,
            timeout=timeout
        )

        return {
            "success": True,
            "output": result.stdout,
            "error": result.stderr if result.returncode != 0 else None
        }

    except subprocess.TimeoutExpired:
        return {"error": f"Command timed out after {timeout}s"}
    except Exception as e:
        return {"error": f"Execution failed: {str(e)}"}

def is_valid_ip(ip):
    """Validate IP address format."""
    import re
    pattern = r'^(\d{1,3}\.){3}\d{1,3}$'
    if not re.match(pattern, ip):
        return False
    return all(0 <= int(octet) <= 255 for octet in ip.split('.'))
```

---

## Contact & Collaboration

This is an ambitious project! Feel free to adjust the timeline and scope based on:
- Available compute resources
- Time you can dedicate per week
- Intermediate results from baseline testing

The modular approach (agent framework → baseline → data collection → fine-tuning) allows you to pivot at any stage if certain approaches don't work out.

**Key insight from your RL work**: Just like the drone landing, reward engineering (here: data quality) will likely be 90% of the success. Focus on high-quality machine documentation over quantity!
